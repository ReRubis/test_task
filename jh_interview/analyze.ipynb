{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass, field\n",
    "from jh_interview.models import TransactionModel, PropertyModel, PostcodeModel\n",
    "\n",
    "from hashlib import md5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Path to the average prices data file.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Constants\n",
    "\n",
    "DATA_DIR = Path('../data/')\n",
    "\"\"\"Path to the data directory.\"\"\"\n",
    "\n",
    "PRICE_PAID_FILE_FIRST = DATA_DIR / 'pp-2019.csv'\n",
    "\"\"\"Path to the first price paid data file.\"\"\"\n",
    "\n",
    "PRICE_PAID_FILE_SECOND = DATA_DIR / 'pp-2020.csv'\n",
    "\"\"\"Path to the second price paid data file.\"\"\"\n",
    "\n",
    "HOUSE_PRICE_INDEX_FILE = DATA_DIR / 'UK-HPI-full-file-2021-03.csv'\n",
    "\"\"\"Path to the house price index data file.\"\"\"\n",
    "\n",
    "AVERAGE_PRICES_FILE = DATA_DIR / 'Average-prices-2021-03.csv'\n",
    "\"\"\"Path to the average prices data file.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_price_paid_data(filepaths: list[Path]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load price paid data from a CSV file.\n",
    "    \"\"\"\n",
    "    column_names = [\n",
    "        'transaction_id', 'price', 'date_of_transfer', 'postcode', 'property_type',\n",
    "        'old_new', 'duration', 'paon', 'saon', 'street', 'locality', 'town_city',\n",
    "        'district', 'country', 'ppd_category_type', 'record_status'\n",
    "        ]\n",
    "\n",
    "    df = pd.concat(\n",
    "        [\n",
    "            pd.read_csv(\n",
    "                filename,\n",
    "                names=column_names,\n",
    "            )\n",
    "            for filename in filepaths\n",
    "        ]\n",
    "    )\n",
    "    df['date_of_transfer'] = pd.to_datetime(df['date_of_transfer'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_price_index_data(filepath: Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load house price index data from a CSV file.\n",
    "    \"\"\"\n",
    "    column_names = [\n",
    "        \"Date\", \"RegionName\", \"AreaCode\", \"AveragePrice\", \"Index\", \"IndexSA\",\n",
    "        \"1m%Change\", \"12m%Change\", \"AveragePriceSA\", \"SalesVolume\",\n",
    "        \"DetachedPrice\", \"DetachedIndex\", \"Detached1m%Change\", \"Detached12m%Change\",\n",
    "        \"SemiDetachedPrice\", \"SemiDetachedIndex\", \"SemiDetached1m%Change\", \"SemiDetached12m%Change\",\n",
    "        \"TerracedPrice\", \"TerracedIndex\", \"Terraced1m%Change\", \"Terraced12m%Change\",\n",
    "        \"FlatPrice\", \"FlatIndex\", \"Flat1m%Change\", \"Flat12m%Change\",\n",
    "        \"CashPrice\", \"CashIndex\", \"Cash1m%Change\", \"Cash12m%Change\", \"CashSalesVolume\",\n",
    "        \"MortgagePrice\", \"MortgageIndex\", \"Mortgage1m%Change\", \"Mortgage12m%Change\", \"MortgageSalesVolume\",\n",
    "        \"FTBPrice\", \"FTBIndex\", \"FTB1m%Change\", \"FTB12m%Change\",\n",
    "        \"FOOPrice\", \"FOOIndex\", \"FOO1m%Change\", \"FOO12m%Change\",\n",
    "        \"NewPrice\", \"NewIndex\", \"New1m%Change\", \"New12m%Change\", \"NewSalesVolume\",\n",
    "        \"OldPrice\", \"OldIndex\", \"Old1m%Change\", \"Old12m%Change\", \"OldSalesVolume\",\n",
    "    ]\n",
    "    df = pd.read_csv(filepath, names=column_names, header=0)\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_average_prices_data(filepath: Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load average prices data from a CSV file.\n",
    "    \"\"\"\n",
    "    column_names = [\n",
    "        \"Date\", \"Region_Name\", \"Area_Code\", \"Average_Price\", \"Monthly_Change\", \"Annual_Change\", \"Average_Price_SA\",\n",
    "    ]\n",
    "    df = pd.read_csv(filepath, names=column_names, header=0)\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_pp = load_price_paid_data(\n",
    "    [PRICE_PAID_FILE_FIRST,\n",
    "    PRICE_PAID_FILE_SECOND]\n",
    ")\n",
    "price_index = load_price_index_data(HOUSE_PRICE_INDEX_FILE)\n",
    "average_prices = load_average_prices_data(AVERAGE_PRICES_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mssql+pyodbc://sa:YourStrong!Passw0rd@localhost:1433/property_db?driver=ODBC+Driver+17+for+SQL+Server\n"
     ]
    }
   ],
   "source": [
    "from jh_interview.database.schemas import Property, Transaction, Postcode\n",
    "from jh_interview.database.db_session import get_session, DB_init, MSSQL_LINK\n",
    "from jh_interview.database.repository import PropertyRepository, TransactionRepository, PostcodeRepository\n",
    "from sqlalchemy.orm import Session\n",
    "\n",
    "print(MSSQL_LINK)\n",
    "DB_init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 10\u001b[0m\n\u001b[1;32m      6\u001b[0m property_data \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m transactions_pp\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m---> 10\u001b[0m     property_id \u001b[38;5;241m=\u001b[39m md5(\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpostcode\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpaon\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msaon\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mencode())\u001b[38;5;241m.\u001b[39mhexdigest()\n\u001b[1;32m     12\u001b[0m     transaction_data\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransaction_id\u001b[39m\u001b[38;5;124m'\u001b[39m: row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransaction_id\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprice\u001b[39m\u001b[38;5;124m'\u001b[39m: row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprice\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate_of_transfer\u001b[39m\u001b[38;5;124m'\u001b[39m: row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate_of_transfer\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproperty_id\u001b[39m\u001b[38;5;124m'\u001b[39m: property_id,\n\u001b[1;32m     17\u001b[0m     })\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m property_id \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m property_data:\n",
      "File \u001b[0;32m/workspaces/tamarix_test/.venv/lib/python3.12/site-packages/pandas/core/series.py:1775\u001b[0m, in \u001b[0;36mSeries.__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1773\u001b[0m \u001b[38;5;66;03m# pylint: disable=invalid-repr-returned\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m repr_params \u001b[38;5;241m=\u001b[39m fmt\u001b[38;5;241m.\u001b[39mget_series_repr_params()\n\u001b[0;32m-> 1775\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_string\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrepr_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspaces/tamarix_test/.venv/lib/python3.12/site-packages/pandas/core/series.py:1874\u001b[0m, in \u001b[0;36mSeries.to_string\u001b[0;34m(self, buf, na_rep, float_format, header, index, length, dtype, name, max_rows, min_rows)\u001b[0m\n\u001b[1;32m   1822\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1823\u001b[0m \u001b[38;5;124;03mRender a string representation of the Series.\u001b[39;00m\n\u001b[1;32m   1824\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1860\u001b[0m \u001b[38;5;124;03m'0    1\\\\n1    2\\\\n2    3'\u001b[39;00m\n\u001b[1;32m   1861\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1862\u001b[0m formatter \u001b[38;5;241m=\u001b[39m fmt\u001b[38;5;241m.\u001b[39mSeriesFormatter(\n\u001b[1;32m   1863\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1864\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1872\u001b[0m     max_rows\u001b[38;5;241m=\u001b[39mmax_rows,\n\u001b[1;32m   1873\u001b[0m )\n\u001b[0;32m-> 1874\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mformatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1876\u001b[0m \u001b[38;5;66;03m# catch contract violations\u001b[39;00m\n\u001b[1;32m   1877\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m/workspaces/tamarix_test/.venv/lib/python3.12/site-packages/pandas/io/formats/format.py:313\u001b[0m, in \u001b[0;36mSeriesFormatter.to_string\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseries)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m([], \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfooter\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    312\u001b[0m index \u001b[38;5;241m=\u001b[39m series\u001b[38;5;241m.\u001b[39mindex\n\u001b[0;32m--> 313\u001b[0m have_header \u001b[38;5;241m=\u001b[39m \u001b[43m_has_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(index, MultiIndex):\n\u001b[1;32m    315\u001b[0m     fmt_index \u001b[38;5;241m=\u001b[39m index\u001b[38;5;241m.\u001b[39m_format_multi(include_names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, sparsify\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/workspaces/tamarix_test/.venv/lib/python3.12/site-packages/pandas/io/formats/format.py:1841\u001b[0m, in \u001b[0;36m_has_names\u001b[0;34m(index)\u001b[0m\n\u001b[1;32m   1834\u001b[0m     result \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   1835\u001b[0m         x \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_number_with_decimal(x) \u001b[38;5;129;01mand\u001b[39;00m x\u001b[38;5;241m.\u001b[39mendswith(decimal) \u001b[38;5;28;01melse\u001b[39;00m x\n\u001b[1;32m   1836\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m trimmed\n\u001b[1;32m   1837\u001b[0m     ]\n\u001b[1;32m   1838\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m-> 1841\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_has_names\u001b[39m(index: Index) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m   1842\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(index, MultiIndex):\n\u001b[1;32m   1843\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m com\u001b[38;5;241m.\u001b[39many_not_none(\u001b[38;5;241m*\u001b[39mindex\u001b[38;5;241m.\u001b[39mnames)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def chunked_data(data, chunk_size):\n",
    "    return (data[i:i+chunk_size] for i in range(0, len(data), chunk_size))\n",
    "\n",
    "with get_session() as session:\n",
    "    transactions_pp['property_id'] = (transactions_pp[['postcode', 'paon', 'saon']].astype(str).apply(lambda x: md5(''.join(x).encode()).hexdigest(), axis=1))\n",
    "\n",
    "    transaction_data = transactions_pp[['transaction_id', 'price', 'date_of_transfer', 'property_id']].to_dict('records')\n",
    "\n",
    "    property_data = defaultdict(lambda: {'transactions': []})\n",
    "\n",
    "    for _, row in transactions_pp.iterrows():\n",
    "        property_id = row['property_id']\n",
    "\n",
    "        property_data[property_id].update({\n",
    "            'unique_id': property_id,\n",
    "            'property_type': row['property_type'] if pd.notna(row['property_type']) else None,\n",
    "            'postcode': row['postcode'] if pd.notna(row['postcode']) else None,\n",
    "            'old_new': row['old_new'] if pd.notna(row['old_new']) else None,\n",
    "            'paon': row['paon'] if pd.notna(row['paon']) else None,\n",
    "            'saon': row['saon'] if pd.notna(row['saon']) else None,\n",
    "            'street': row['street'] if pd.notna(row['street']) else None,\n",
    "            'locality': row['locality'] if pd.notna(row['locality']) else None,\n",
    "            'town_city': row['town_city'] if pd.notna(row['town_city']) else None,\n",
    "            'district': row['district'] if pd.notna(row['district']) else None,\n",
    "            'country': row['country'] if pd.notna(row['country']) else None,\n",
    "        })\n",
    "\n",
    "        property_data[property_id]['transactions'].append(row['transaction_id'])\n",
    "        \n",
    "    property_data = list(property_data.values())\n",
    "\n",
    "    print(\"Starting to insert transaction data\")\n",
    "    for chunk in chunked_data(transaction_data, 1000):\n",
    "        session.bulk_insert_mappings(Transaction, chunk)\n",
    "\n",
    "    print('Starting to insert property data')\n",
    "    for chunk in chunked_data(property_data, 1000):\n",
    "        session.bulk_insert_mappings(Property, chunk)\n",
    "\n",
    "    session.commit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
