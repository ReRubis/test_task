{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass, field\n",
    "from jh_interview.models import TransactionModel, PropertyModel, PostcodeModel\n",
    "\n",
    "from hashlib import md5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Path to the average prices data file.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Constants\n",
    "\n",
    "DATA_DIR = Path('../data/')\n",
    "\"\"\"Path to the data directory.\"\"\"\n",
    "\n",
    "PRICE_PAID_FILE_FIRST = DATA_DIR / 'pp-2019.csv'\n",
    "\"\"\"Path to the first price paid data file.\"\"\"\n",
    "\n",
    "PRICE_PAID_FILE_SECOND = DATA_DIR / 'pp-2020.csv'\n",
    "\"\"\"Path to the second price paid data file.\"\"\"\n",
    "\n",
    "HOUSE_PRICE_INDEX_FILE = DATA_DIR / 'UK-HPI-full-file-2021-03.csv'\n",
    "\"\"\"Path to the house price index data file.\"\"\"\n",
    "\n",
    "AVERAGE_PRICES_FILE = DATA_DIR / 'Average-prices-2021-03.csv'\n",
    "\"\"\"Path to the average prices data file.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_price_paid_data(filepaths: list[Path]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load price paid data from a CSV file.\n",
    "    \"\"\"\n",
    "    column_names = [\n",
    "        'transaction_id', 'price', 'date_of_transfer', 'postcode', 'property_type',\n",
    "        'old_new', 'duration', 'paon', 'saon', 'street', 'locality', 'town_city',\n",
    "        'district', 'country', 'ppd_category_type', 'record_status'\n",
    "        ]\n",
    "\n",
    "    df = pd.concat(\n",
    "        [\n",
    "            pd.read_csv(\n",
    "                filename,\n",
    "                names=column_names,\n",
    "            )\n",
    "            for filename in filepaths\n",
    "        ]\n",
    "    )\n",
    "    df['date_of_transfer'] = pd.to_datetime(df['date_of_transfer'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_price_index_data(filepath: Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load house price index data from a CSV file.\n",
    "    \"\"\"\n",
    "    column_names = [\n",
    "        \"Date\", \"RegionName\", \"AreaCode\", \"AveragePrice\", \"Index\", \"IndexSA\",\n",
    "        \"1m%Change\", \"12m%Change\", \"AveragePriceSA\", \"SalesVolume\",\n",
    "        \"DetachedPrice\", \"DetachedIndex\", \"Detached1m%Change\", \"Detached12m%Change\",\n",
    "        \"SemiDetachedPrice\", \"SemiDetachedIndex\", \"SemiDetached1m%Change\", \"SemiDetached12m%Change\",\n",
    "        \"TerracedPrice\", \"TerracedIndex\", \"Terraced1m%Change\", \"Terraced12m%Change\",\n",
    "        \"FlatPrice\", \"FlatIndex\", \"Flat1m%Change\", \"Flat12m%Change\",\n",
    "        \"CashPrice\", \"CashIndex\", \"Cash1m%Change\", \"Cash12m%Change\", \"CashSalesVolume\",\n",
    "        \"MortgagePrice\", \"MortgageIndex\", \"Mortgage1m%Change\", \"Mortgage12m%Change\", \"MortgageSalesVolume\",\n",
    "        \"FTBPrice\", \"FTBIndex\", \"FTB1m%Change\", \"FTB12m%Change\",\n",
    "        \"FOOPrice\", \"FOOIndex\", \"FOO1m%Change\", \"FOO12m%Change\",\n",
    "        \"NewPrice\", \"NewIndex\", \"New1m%Change\", \"New12m%Change\", \"NewSalesVolume\",\n",
    "        \"OldPrice\", \"OldIndex\", \"Old1m%Change\", \"Old12m%Change\", \"OldSalesVolume\",\n",
    "    ]\n",
    "    df = pd.read_csv(filepath, names=column_names, header=0)\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_average_prices_data(filepath: Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load average prices data from a CSV file.\n",
    "    \"\"\"\n",
    "    column_names = [\n",
    "        \"Date\", \"Region_Name\", \"Area_Code\", \"Average_Price\", \"Monthly_Change\", \"Annual_Change\", \"Average_Price_SA\",\n",
    "    ]\n",
    "    df = pd.read_csv(filepath, names=column_names, header=0)\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_pp = load_price_paid_data(\n",
    "    [PRICE_PAID_FILE_FIRST,\n",
    "    PRICE_PAID_FILE_SECOND]\n",
    ")\n",
    "price_index = load_price_index_data(HOUSE_PRICE_INDEX_FILE)\n",
    "average_prices = load_average_prices_data(AVERAGE_PRICES_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mssql+pyodbc://sa:YourStrong!Passw0rd@localhost:1433/property_db?driver=ODBC+Driver+17+for+SQL+Server\n"
     ]
    }
   ],
   "source": [
    "from jh_interview.database.schemas import Property, Transaction, Postcode\n",
    "from jh_interview.database.db_session import get_session, DB_init, MSSQL_LINK\n",
    "from jh_interview.database.repository import PropertyRepository, TransactionRepository, PostcodeRepository\n",
    "from sqlalchemy.orm import Session\n",
    "\n",
    "print(MSSQL_LINK)\n",
    "DB_init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to insert transaction data\n",
      "Starting to insert property data\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def chunked_data(data, chunk_size):\n",
    "    return (data[i:i+chunk_size] for i in range(0, len(data), chunk_size))\n",
    "\n",
    "with get_session() as session:\n",
    "    transactions_pp['property_id'] = (transactions_pp[['postcode', 'paon', 'saon']].astype(str).apply(lambda x: md5(''.join(x).encode()).hexdigest(), axis=1))\n",
    "\n",
    "    transaction_data = transactions_pp[['transaction_id', 'price', 'date_of_transfer', 'property_id']].to_dict('records')\n",
    "\n",
    "    property_data = defaultdict(lambda: {'transactions': []})\n",
    "\n",
    "    for _, row in transactions_pp.iterrows():\n",
    "        property_id = row['property_id']\n",
    "\n",
    "        property_data[property_id].update({\n",
    "            'unique_id': property_id,\n",
    "            'property_type': row['property_type'] if pd.notna(row['property_type']) else None,\n",
    "            'postcode': row['postcode'] if pd.notna(row['postcode']) else None,\n",
    "            'old_new': row['old_new'] if pd.notna(row['old_new']) else None,\n",
    "            'paon': row['paon'] if pd.notna(row['paon']) else None,\n",
    "            'saon': row['saon'] if pd.notna(row['saon']) else None,\n",
    "            'street': row['street'] if pd.notna(row['street']) else None,\n",
    "            'locality': row['locality'] if pd.notna(row['locality']) else None,\n",
    "            'town_city': row['town_city'] if pd.notna(row['town_city']) else None,\n",
    "            'district': row['district'] if pd.notna(row['district']) else None,\n",
    "            'country': row['country'] if pd.notna(row['country']) else None,\n",
    "        })\n",
    "\n",
    "        property_data[property_id]['transactions'].append(row['transaction_id'])\n",
    "        \n",
    "    property_data = list(property_data.values())\n",
    "\n",
    "    print(\"Starting to insert transaction data\")\n",
    "    for chunk in chunked_data(transaction_data, 1000):\n",
    "        session.bulk_insert_mappings(Transaction, chunk)\n",
    "\n",
    "    print('Starting to insert property data')\n",
    "    for chunk in chunked_data(property_data, 1000):\n",
    "        session.bulk_insert_mappings(Property, chunk)\n",
    "\n",
    "    session.commit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
